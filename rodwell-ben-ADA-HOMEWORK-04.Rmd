---
title: "Homework_4"
author: "Ben Rodwell"
date: "April 9, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::opts_chunk$set(
    fig.path = "img/"
)
```

```{r}
# Load the data
library(curl)
f <- curl("https://raw.githubusercontent.com/difiore/ADA-2019/master/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = TRUE)
head(d)
```



# [1]
## Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).
```{r}
model <- lm(data = d, formula = log(HomeRange_km2) ~ log(Body_mass_female_mean))
model
summary(model)
par(mfrow = c(2,2))

# Coefficients
model$coefficients
```






# [2]
## Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the appropriate coefficients. This generates a sampling distribution for each β coefficient. Plot a histogram of these sampling distributions.

```{r}
n <- length(d[,1]) # Number of observations
dsample <- d[sample(nrow(d), n, replace = T), ]
head(dsample)
str(dsample)

## Loop to repeat it 1000 times while storing the beta coefficients
n <- length(d[,1]) # Number of observations/rows in the dataset
b <- 1000
beta0 <- rep(0,b) # empty vector for bootstrapped beta0 values
beta1 <- rep(0,b) # empty vector for bootstrapped beta1 values
for (i in 1:b){
  dsample <- d[sample(nrow(d), n, replace = T), ]
  model <- lm(data = dsample, formula = log(HomeRange_km2) ~ log(Body_mass_female_mean))
  beta0[i] <- model$coefficients[1] # storing the beta0 value in the empty vector
  beta1[i] <- model$coefficients[2] # storing the beta1 value in the empty vector
  }
head(beta1)
head(beta0)

## Histograms of the bootstrapped beta coefficients
par(mfrow = c(1,2))
hist(beta0, breaks = 20)
hist(beta1, breaks = 20)
par(mfrow = c(1,1))
```



# [3]
## Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap.

```{r}
SEbeta0 <- sd(beta0)
SEbeta0
SEbeta1 <- sd(beta1)
SEbeta1
```


# [4]
## Also determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

```{r}
beta0confupper <- mean(beta0) + qnorm(0.975) * SEbeta0
beta0conflower <- mean(beta0) - qnorm(0.975) * SEbeta0
beta0conf <- cbind(beta0conflower, beta0confupper)
beta0conf

beta1confupper <- mean(beta1) + qnorm(0.975) * SEbeta1
beta1conflower <- mean(beta1) - qnorm(0.975) * SEbeta1
beta1conf <- cbind(beta1conflower, beta1confupper)
beta1conf 
```


# [5]
## How does your answer to part [3] compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?


In the original model that was ran in step 1 the coefficients for beta0 = 0.67293, and beta1 = 0.08488, and the estimated ones from the sampling distribution are beta0 = .6032588, and beta1 = 0.07758149 (the sampling distribution estimates will change each time the bootstrap is ran, but should be similar to these values). The standard error estimates from the sampling distributions is fairly close to the values for the beta coefficients from the original model.


# [6]
## How does your answer to part [4] compare to the 95% CI estimated from your entire dataset?

The confidence intervals that we have estimated are consistent with those of the original linear model.
```{r}
confint(model)
beta0conf
beta1conf
```